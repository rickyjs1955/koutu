// filepath: /backend/src/tests/integration/db.int.test.ts

import pg, { Pool } from 'pg';
import { setupTestDatabase, teardownTestDatabase } from '../../utils/testSetup';

describe('Integration tests for db.ts', () => {
    let pool: Pool;
    
    beforeAll(async () => {
        await setupTestDatabase();  // Setup koutu-postgres-test database
        
        // Create a new connection pool for testing
        pool = new Pool({
            host: 'localhost',
            port: 5433,
            user: 'postgres',
            password: 'password',
            database: 'koutu-postgres-test',
            connectionTimeoutMillis: 5000
        });
    });
    
    afterAll(async () => {
        // Clean up by dropping the tables and closing the connection pool
        await teardownTestDatabase();
        await pool.end();
    });
    
    describe('Database Connection', () => {
        it('should connect to the database', async () => {
            // Truncate table before each test
            await pool.query('TRUNCATE TABLE test_table');
            
            // Insert data for testing
            await pool.query(`INSERT INTO test_table (value) VALUES ('test')`);

            const res = await pool.query('SELECT * FROM test_table');
            expect(res.rows).toHaveLength(1);   // Expecting one row in the result set
        });
    });
    
    describe('Basic CRUD Operations', () => {
        it('should insert data into the database', async () => {
            // Truncate table before each test
            await pool.query('TRUNCATE TABLE test_table');
            
            const res = await pool.query(`INSERT INTO test_table (value) VALUES ('test') RETURNING *`);
            expect(res.rows).toHaveLength(1);   // Expecting one row in the result set after insertion
        });

        it('should delete data from the database', async () => {
            // Truncate table before each test
            await pool.query('TRUNCATE TABLE test_table');
            
            const res = await pool.query(`DELETE FROM test_table WHERE value='test' RETURNING *`);
            expect(res.rows).toHaveLength(0);   // Expecting no rows in the result set after deletion
        });

        it('should update data in the database', async () => {
            // Insert data for testing
            await pool.query(`INSERT INTO test_table (value) VALUES ('test')`);
            
            const res = await pool.query(`UPDATE test_table SET value='updated' WHERE value='test' RETURNING *`);
            expect(res.rows[0].value).toBe('updated');   // Expecting updated row in the result set after update
        });

        it('should select a specific value from the table', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            await pool.query(`INSERT INTO test_table (value) VALUES ('test'), ('another')`);
            
            const res = await pool.query(`SELECT * FROM test_table WHERE value = 'test'`);
            expect(res.rows).toHaveLength(1);
            expect(res.rows[0].value).toBe('test');
        });
    });

    describe('Error Handling', () => {
        it('should handle errors when querying a non-existent table', async () => {
            try {
                const res = await pool.query('SELECT * FROM non_existent_table');
            } catch (error) {
                expect(error).toBeDefined();   // Expecting an error to be thrown
            }
        });

        // Tests previously known as 'should handle duplicate key violations'
        it('should explicitly catch and validate duplicate key violation errors', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            await pool.query(`INSERT INTO test_table (value) VALUES ('duplicate')`);

            try {
                await pool.query(`INSERT INTO test_table (value) VALUES ('duplicate')`);
            } catch (error) {
                // First, assert the specific type at runtime for the test report
                expect(error).toBeInstanceOf(pg.DatabaseError);

                // Then, use a type guard for TypeScript to correctly narrow the type
                if (error instanceof pg.DatabaseError) {
                    // Now TypeScript knows 'error' is a pg.DatabaseError (which extends Error)
                    expect(error.message).toContain('duplicate key');
                    // You can also assert on specific properties like the SQLSTATE error code
                    // expect(error.code).toBe('23505'); // Example for PostgreSQL unique_violation code
                } else {
                    // This 'else' block catches anything that is NOT a pg.DatabaseError,
                    // which might include other types of Errors or entirely non-Error values.
                    fail('Expected a pg.DatabaseError for duplicate key violation, but received a different error type.');
                }
            }
        });
    });
    
    describe('Parameterized Queries', () => {
        it('should insert data using parameterized queries', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            
            const res = await pool.query(`INSERT INTO test_table (value) VALUES ($1) RETURNING *`, ['param']);
            expect(res.rows[0].value).toBe('param');
        });
    });

    describe('Transactions', () => {
        it('should commit a transaction', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            
            await pool.query(`BEGIN`);
            await pool.query(`INSERT INTO test_table (value) VALUES ('committed')`);
            await pool.query(`COMMIT`);
            
            const res = await pool.query(`SELECT * FROM test_table`);
            expect(res.rows).toHaveLength(1);
            expect(res.rows[0].value).toBe('committed');
        });

        it('should rollback a transaction', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            
            await pool.query(`BEGIN`);
            await pool.query(`INSERT INTO test_table (value) VALUES ('rolled_back')`);
            await pool.query(`ROLLBACK`);
            
            const res = await pool.query(`SELECT * FROM test_table`);
            expect(res.rows).toHaveLength(0);
        });
    });

    describe('Edge Cases', () => {
        // Tests previously known as 'should handle duplicate key violations'
        it('should concisely assert duplicate key violation errors using Jest matchers', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            await pool.query(`INSERT INTO test_table (value) VALUES ('duplicate')`);

            await expect(
                pool.query(`INSERT INTO test_table (value) VALUES ('duplicate')`)
            ).rejects.toThrow(
                expect.objectContaining({
                code: '23505',                    // unique_violation
                message: expect.stringContaining('duplicate key')
                })
            );
        });
    });

    describe('Pagination', () => {
        it('should retrieve data with LIMIT and OFFSET', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            await pool.query(`INSERT INTO test_table (value) VALUES ('a'), ('b'), ('c'), ('d')`);
            
            const res = await pool.query(`SELECT * FROM test_table ORDER BY id LIMIT 2 OFFSET 1`);
            expect(res.rows).toHaveLength(2);
            expect(res.rows[0].value).toBe('b');
            expect(res.rows[1].value).toBe('c');
        });
    });

    describe('Schema Validation', () => {
        it('should verify table structure', async () => {
            const res = await pool.query(`SELECT * FROM information_schema.tables WHERE table_name = 'test_table'`);
            expect(res.rows).toHaveLength(1);
            expect(res.rows[0].table_name).toBe('test_table');
        });
    });

    describe('Connection Resilience', () => {
        it('should handle invalid credentials gracefully', async () => {
            const invalidPool = new Pool({
                host: 'localhost',
                port: 5433,
                user: 'invalid_user',
                password: 'wrong_password',
                database: 'koutu-postgres-test',
                connectionTimeoutMillis: 1000
            });
            
            await expect(
                invalidPool.query('SELECT 1')
            ).rejects.toThrow();
            
            await invalidPool.end();
        });
        
        it('should handle connection timeouts appropriately', async () => {
            // Using a non-routable IP to force timeout
            const timeoutPool = new Pool({
                host: '10.255.255.1', // Non-routable IP that should timeout
                port: 5433,
                user: 'postgres',
                password: 'password',
                database: 'koutu-postgres-test',
                connectionTimeoutMillis: 1000 // Short timeout for quick test
            });
            
            await expect(
                timeoutPool.query('SELECT 1')
            ).rejects.toThrow();
            
            await timeoutPool.end();
        });
        
        it('should handle connection pool limits', async () => {
            // Create a pool with a very small max client limit
            const limitedPool = new Pool({
                host: 'localhost',
                port: 5433,
                user: 'postgres',
                password: 'password',
                database: 'koutu-postgres-test',
                max: 2, // Only allow 2 clients
                connectionTimeoutMillis: 3000 // Increase timeout
            });
            
            try {
                // Rather than using concurrent queries with pg_sleep which can timeout,
                // let's create a controlled test where we manually check out clients
                const client1 = await limitedPool.connect();
                const client2 = await limitedPool.connect();
                
                // Both clients should be usable
                await client1.query('SELECT 1');
                await client2.query('SELECT 1');
                
                // A third client request should be queued but not error
                const clientPromise = limitedPool.connect();
                
                // Release a connection to allow the third request to proceed
                client1.release();
                
                // Now the third client should be able to connect
                const client3 = await clientPromise;
                await client3.query('SELECT 1');
                client3.release();
                client2.release();
                
                // Test passed if we got here without timeout
                expect(true).toBe(true);
            } finally {
                await limitedPool.end();
            }
        });
    });

    describe('Data Integrity Constraints', () => {
        it('should handle NOT NULL constraint violations', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            
            // Assuming value column is NOT NULL
            await expect(
                pool.query(`INSERT INTO test_table (value) VALUES (NULL)`)
            ).rejects.toThrow(
                expect.objectContaining({
                    message: expect.stringContaining('null value')
                })
            );
        });
        
        it('should handle foreign key constraint violations', async () => {
            // Create parent and child tables for testing foreign keys
            await pool.query(`
                CREATE TABLE IF NOT EXISTS parent_table (
                    id SERIAL PRIMARY KEY,
                    name TEXT NOT NULL
                )
            `);
            
            await pool.query(`
                CREATE TABLE IF NOT EXISTS child_table (
                    id SERIAL PRIMARY KEY,
                    parent_id INTEGER REFERENCES parent_table(id),
                    description TEXT
                )
            `);
            
            // Try to insert child record with non-existent parent_id
            await expect(
                pool.query(`INSERT INTO child_table (parent_id, description) VALUES (999, 'orphaned record')`)
            ).rejects.toThrow(
                expect.objectContaining({
                    message: expect.stringContaining('foreign key constraint')
                })
            );
            
            // Clean up test tables
            await pool.query(`DROP TABLE IF EXISTS child_table`);
            await pool.query(`DROP TABLE IF EXISTS parent_table`);
        });
    });

    describe('SQL Injection Protection', () => {
        it('should prevent SQL injection when using parameterized queries', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            await pool.query(`INSERT INTO test_table (value) VALUES ('safe_value')`);
            
            // Malicious input that would become an attack if directly inserted into a query
            const maliciousInput = "'; DELETE FROM test_table; --";
            
            // Use parameterized query to safely handle the input
            await pool.query(`INSERT INTO test_table (value) VALUES ($1)`, [maliciousInput]);
            
            // If injection was successful, this would delete all records
            // So we check that both records still exist
            const res = await pool.query(`SELECT * FROM test_table`);
            expect(res.rows).toHaveLength(2);
            expect(res.rows.some(row => row.value === maliciousInput)).toBe(true);
        });
        
        it('should demonstrate vulnerability when not using parameterized queries', async () => {
            // This test is educational to show the risk - real code should NEVER do this
            await pool.query('TRUNCATE TABLE test_table');
            await pool.query(`INSERT INTO test_table (value) VALUES ('safe_value')`);
            
            // Define a vulnerable query-building function (DEMONSTRATION ONLY)
            const buildUnsafeQuery = (value: string) => {
                // DON'T DO THIS in real code - this simulates vulnerable code
                return `INSERT INTO test_table (value) VALUES ('${value}')`;
            };
            
            // Safe input works as expected
            const safeInput = "normal";
            await pool.query(buildUnsafeQuery(safeInput));
            
            // But with malicious input, the query structure is altered
            const maliciousInput = "'); DELETE FROM test_table; --";
            
            // Execute the query with vulnerability - this would be exploitable
            // We expect it either to cause an error or alter the database in unexpected ways
            try {
                await pool.query(buildUnsafeQuery(maliciousInput));
                
                // If no error, check if records were affected
                const res = await pool.query(`SELECT * FROM test_table`);
                
                // Document the vulnerability if records were deleted 
                if (res.rows.length < 2) {
                    console.log('SQL Injection vulnerability demonstrated - records were deleted');
                }
            } catch (error) {
                // The query might throw an error, which is also a sign of vulnerability
                expect(error).toBeDefined();
                console.log('SQL Injection vulnerability demonstrated - query syntax error');
            }
        });
    });

    describe('Advanced Transaction Scenarios', () => {
        it('should handle transaction isolation levels', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            
            // Create a second client to simulate concurrent transactions
            const client1 = await pool.connect();
            const client2 = await pool.connect();
            
            try {
                // Insert initial data outside of transactions
                await pool.query(`INSERT INTO test_table (value) VALUES ('initial')`);
                
                // Start transaction with READ COMMITTED isolation in first client (default in PostgreSQL)
                await client1.query('BEGIN');
                
                // Start transaction with READ COMMITTED isolation in second client 
                await client2.query('BEGIN');
                
                // Both clients can see the initial data
                const initialCheck1 = await client1.query('SELECT * FROM test_table');
                const initialCheck2 = await client2.query('SELECT * FROM test_table');
                expect(initialCheck1.rows).toHaveLength(1);
                expect(initialCheck2.rows).toHaveLength(1);
                
                // First client modifies data
                await client1.query(`INSERT INTO test_table (value) VALUES ('tx1_value')`);
                
                // First client can see its own modification
                const afterInsert1 = await client1.query('SELECT * FROM test_table');
                expect(afterInsert1.rows).toHaveLength(2);
                
                // Second client should NOT see the modification until first client commits
                const beforeCommit2 = await client2.query('SELECT * FROM test_table');
                expect(beforeCommit2.rows).toHaveLength(1); // Only sees initial data
                
                // Commit first transaction
                await client1.query('COMMIT');
                
                // NOW second client should see the committed data (in READ COMMITTED isolation)
                const afterCommit2 = await client2.query('SELECT * FROM test_table');
                expect(afterCommit2.rows).toHaveLength(2);
                
                // Commit second transaction
                await client2.query('COMMIT');
            } finally {
                // Always release clients back to the pool
                client1.release();
                client2.release();
            }
        });
        
        it('should detect and handle deadlock scenarios', async () => {
            // Ensure clean state before test
            await pool.query('DROP TABLE IF EXISTS second_table');
            await pool.query('TRUNCATE TABLE test_table');
            
            // Create second test table
            await pool.query(`
                CREATE TABLE IF NOT EXISTS second_table (
                    id SERIAL PRIMARY KEY,
                    value TEXT
                )
            `);
            
            // Insert initial data
            await pool.query(`INSERT INTO test_table (value) VALUES ('resource1')`);
            await pool.query(`INSERT INTO second_table (value) VALUES ('resource2')`);
            
            // Get two clients for concurrent transactions
            const client1 = await pool.connect();
            const client2 = await pool.connect();
            
            try {
                // Start transactions
                await client1.query('BEGIN');
                await client2.query('BEGIN');
                
                // T1 locks first table
                await client1.query('SELECT * FROM test_table FOR UPDATE');
                
                // T2 locks second table
                await client2.query('SELECT * FROM second_table FOR UPDATE');
                
                // Use Promise.race to test for deadlock
                // Only run the deadlock scenario for a short time to avoid test timeouts
                const timeoutPromise = new Promise(resolve => setTimeout(resolve, 2000));
                
                const deadlockPromise = Promise.all([
                    // T1 tries to lock second table
                    client1.query('SELECT * FROM second_table FOR UPDATE')
                        .catch(e => { return { error: e }; }),
                    // T2 tries to lock first table
                    client2.query('SELECT * FROM test_table FOR UPDATE')
                        .catch(e => { return { error: e }; })
                ]);
                
                // Wait for either deadlock or timeout
                const result = await Promise.race([deadlockPromise, timeoutPromise]);
                
                // Need to rollback both transactions in any case
                await client1.query('ROLLBACK').catch(() => {});
                await client2.query('ROLLBACK').catch(() => {});
                
                // If we got a deadlock result, verify it
                if (result !== timeoutPromise) {
                    const results = result as Array<any>;
                    const hasDeadlockError = results.some(r => 
                        r?.error instanceof pg.DatabaseError && 
                        (r.error.code === '40P01' || r.error.message.includes('deadlock'))
                    );
                    
                    // In some environments you might not be able to reliably create a deadlock
                    // so we'll just log but not fail the test
                    if (hasDeadlockError) {
                        console.log('Successfully detected a deadlock condition');
                    } else {
                        console.log('No deadlock was detected in the time limit');
                    }
                } else {
                    console.log('Timeout reached without deadlock detection');
                }
                
            } finally {
                // Make absolutely sure clients are released
                client1.release();
                client2.release();
            }
            
            // Clean up in a separate try/catch to ensure it happens
            try {
                await pool.query('DROP TABLE IF EXISTS second_table');
            } catch (error) {
                console.error('Error cleaning up test tables:', error);
            }
        });
    });

    describe('Performance with Large Datasets', () => {
        it('should handle large result sets efficiently', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            
            // Create a larger dataset - in a real scenario, this might be even larger
            // Using a batch approach to insert many records
            const batchSize = 500;
            const totalRecords = 2000; // A reasonable size for a test
            
            for (let i = 0; i < totalRecords; i += batchSize) {
                const values = Array.from({ length: Math.min(batchSize, totalRecords - i) }, 
                    (_, j) => `('large_dataset_value_${i + j}')`).join(',');
                
                await pool.query(`INSERT INTO test_table (value) VALUES ${values}`);
            }
            
            // Verify total count
            const countResult = await pool.query('SELECT COUNT(*) FROM test_table');
            expect(parseInt(countResult.rows[0].count)).toBe(totalRecords);
            
            // Test pagination performance with varying page sizes
            const pageSizes = [10, 50, 100];
            
            for (const pageSize of pageSizes) {
                const startTime = Date.now();
                
                // Fetch first page
                const res = await pool.query(
                    'SELECT * FROM test_table ORDER BY id LIMIT $1',
                    [pageSize]
                );
                
                const duration = Date.now() - startTime;
                
                // Assertions about performance
                expect(res.rows).toHaveLength(pageSize);
                
                // Log performance metrics - in a real test you might define time limits
                console.log(`Page size ${pageSize} query took ${duration}ms`);
                
                // Optional soft assertion on performance - adjust threshold based on environment
                expect(duration).toBeLessThan(1000); // Should be quick for this test size
            }
        });
        
        it('should perform efficiently with indexed vs non-indexed queries', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            
            // Generate unique values to avoid duplicate key violations
            const values = [];
            for (let i = 0; i < 1000; i++) {
                values.push(`unique_value_${i}`);
            }
            
            // Use a batch approach for faster insertion
            const batchSize = 100;
            for (let i = 0; i < values.length; i += batchSize) {
                const batch = values.slice(i, i + batchSize);
                const placeholders = batch.map((_, idx) => `($${idx + 1})`).join(',');
                await pool.query(
                    `INSERT INTO test_table (value) VALUES ${placeholders}`,
                    batch
                );
            }
            
            // Define a search value we'll use for both tests
            const searchValue = values[500];
            
            // Query without index
            const startNoIndex = Date.now();
            await pool.query(`SELECT * FROM test_table WHERE value = $1`, [searchValue]);
            const durationNoIndex = Date.now() - startNoIndex;
            
            // Create an index
            await pool.query('CREATE INDEX IF NOT EXISTS idx_test_table_value ON test_table(value)');
            
            // Query with index
            const startWithIndex = Date.now();
            await pool.query(`SELECT * FROM test_table WHERE value = $1`, [searchValue]);
            const durationWithIndex = Date.now() - startWithIndex;
            
            // Clean up
            await pool.query('DROP INDEX IF EXISTS idx_test_table_value');
            
            // Log performance comparison
            console.log(`Query without index: ${durationNoIndex}ms`);
            console.log(`Query with index: ${durationWithIndex}ms`);
            
            // We don't assert on specific timing as it may vary by environment
            // But we do verify the test ran successfully
            expect(true).toBe(true);
        });
    });

    describe('Schema Evolution', () => {
        it('should handle adding a new column to existing table', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            await pool.query(`INSERT INTO test_table (value) VALUES ('before_migration')`);
            
            // Add a new column to the table
            await pool.query(`ALTER TABLE test_table ADD COLUMN IF NOT EXISTS metadata TEXT`);
            
            // Verify existing data is preserved
            const res1 = await pool.query(`SELECT * FROM test_table`);
            expect(res1.rows).toHaveLength(1);
            expect(res1.rows[0].value).toBe('before_migration');
            expect(res1.rows[0].metadata).toBeNull(); // New column should be NULL for existing rows
            
            // Insert data with the new column
            await pool.query(
                `INSERT INTO test_table (value, metadata) VALUES ($1, $2)`,
                ['after_migration', 'meta_value']
            );
            
            // Verify both old and new data
            const res2 = await pool.query(`SELECT * FROM test_table ORDER BY id`);
            expect(res2.rows).toHaveLength(2);
            expect(res2.rows[0].value).toBe('before_migration');
            expect(res2.rows[0].metadata).toBeNull();
            expect(res2.rows[1].value).toBe('after_migration');
            expect(res2.rows[1].metadata).toBe('meta_value');
            
            // Clean up the added column
            await pool.query(`ALTER TABLE test_table DROP COLUMN IF EXISTS metadata`);
        });
        
        it('should handle changing column constraints', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            
            // Add a temporary column with a constraint
            await pool.query(`ALTER TABLE test_table ADD COLUMN IF NOT EXISTS temp_col TEXT CHECK (length(temp_col) <= 5)`);
            
            // Insert valid data
            await pool.query(
                `INSERT INTO test_table (value, temp_col) VALUES ($1, $2)`, 
                ['constraint_test_1', 'short']
            );
            
            // Try to insert invalid data that violates the constraint
            await expect(
                pool.query(
                    `INSERT INTO test_table (value, temp_col) VALUES ($1, $2)`,
                    ['constraint_test_2', 'too_long']
                )
            ).rejects.toThrow(
                expect.objectContaining({
                    message: expect.stringContaining('check constraint')
                })
            );
            
            // Modify the constraint to allow longer values
            await pool.query(`
                ALTER TABLE test_table DROP CONSTRAINT IF EXISTS test_table_temp_col_check;
                ALTER TABLE test_table ADD CONSTRAINT test_table_temp_col_check CHECK (length(temp_col) <= 10)
            `);
            
            // Now the previously invalid data should be allowed
            await pool.query(
                `INSERT INTO test_table (value, temp_col) VALUES ($1, $2)`,
                ['constraint_test_3', 'longer_ok']
            );
            
            // Clean up
            await pool.query(`ALTER TABLE test_table DROP COLUMN IF EXISTS temp_col`);
        });
    });

    describe('Edge Case Data Inputs', () => {
        it('should handle very long string values', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            
            // Generate a very long string
            const longString = 'a'.repeat(5000);
            
            // Insert the long string
            await pool.query(`INSERT INTO test_table (value) VALUES ($1)`, [longString]);
            
            // Retrieve and verify
            const res = await pool.query(`SELECT * FROM test_table`);
            expect(res.rows).toHaveLength(1);
            expect(res.rows[0].value).toBe(longString);
            expect(res.rows[0].value.length).toBe(5000);
        });
        
        it('should handle special characters and Unicode', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            
            // Test various special characters
            const specialChars = [
                'Text with spaces and punctuation!@#$%^&*()',
                'Unicode: √±√°√©√≠√≥√∫√º',
                'Emojis: üòÄüöÄüåç',
                'Control chars: \t\n\r',
                'SQL-special: \'; DROP TABLE--',
                'JSON: {"key": "value"}',
                'XML: <tag>content</tag>'
            ];
            
            // Insert all special characters
            for (const char of specialChars) {
                await pool.query(`INSERT INTO test_table (value) VALUES ($1)`, [char]);
            }
            
            // Verify each was stored correctly
            for (const char of specialChars) {
                const res = await pool.query(`SELECT * FROM test_table WHERE value = $1`, [char]);
                expect(res.rows).toHaveLength(1);
                expect(res.rows[0].value).toBe(char);
            }
        });
        
        it('should handle binary data if supported', async () => {
            await pool.query('TRUNCATE TABLE test_table');
            
            try {
                // Create a table with bytea column if not exists
                await pool.query(`
                    CREATE TABLE IF NOT EXISTS binary_test_table (
                        id SERIAL PRIMARY KEY,
                        bin_data BYTEA
                    )
                `);
                
                // Create some binary data (a simple Buffer in Node.js)
                const binaryData = Buffer.from([0x01, 0x02, 0x03, 0xFF, 0xFE]);
                
                // Insert binary data
                await pool.query(
                    `INSERT INTO binary_test_table (bin_data) VALUES ($1)`,
                    [binaryData]
                );
                
                // Retrieve binary data
                const res = await pool.query(`SELECT * FROM binary_test_table`);
                expect(res.rows).toHaveLength(1);
                
                // In pg, binary data is returned as a Buffer
                const retrievedData = res.rows[0].bin_data;
                expect(Buffer.isBuffer(retrievedData)).toBe(true);
                
                // Compare the retrieved data with original
                expect(retrievedData.equals(binaryData)).toBe(true);
                
            } finally {
                // Clean up 
                await pool.query(`DROP TABLE IF EXISTS binary_test_table`);
            }
        });
    });

    describe('Cleanup Robustness', () => {
        it('should handle cleanup with dependent tables', async () => {
            // Create parent and child tables with foreign key constraints
            await pool.query(`
                CREATE TABLE IF NOT EXISTS parent_cleanup (
                    id SERIAL PRIMARY KEY,
                    name TEXT NOT NULL
                )
            `);
            
            await pool.query(`
                CREATE TABLE IF NOT EXISTS child_cleanup (
                    id SERIAL PRIMARY KEY,
                    parent_id INTEGER REFERENCES parent_cleanup(id) ON DELETE CASCADE,
                    description TEXT
                )
            `);
            
            // Insert test data
            await pool.query(`INSERT INTO parent_cleanup (name) VALUES ('parent1')`);
            const parentRes = await pool.query(`SELECT id FROM parent_cleanup LIMIT 1`);
            const parentId = parentRes.rows[0].id;
            
            await pool.query(
                `INSERT INTO child_cleanup (parent_id, description) VALUES ($1, 'child1')`,
                [parentId]
            );
            
            // Try to truncate parent table (would fail without CASCADE)
            try {
                await pool.query(`TRUNCATE TABLE parent_cleanup`);
                fail('Should not be able to truncate without CASCADE when foreign keys exist');
            } catch (error) {
                expect(error).toBeDefined();
                expect(error instanceof pg.DatabaseError).toBe(true);
            }
            
            // Proper way to clean up with dependencies
            await pool.query(`TRUNCATE TABLE parent_cleanup CASCADE`);
            
            // Verify both tables are empty
            const parentCount = await pool.query(`SELECT COUNT(*) FROM parent_cleanup`);
            const childCount = await pool.query(`SELECT COUNT(*) FROM child_cleanup`);
            
            expect(parseInt(parentCount.rows[0].count)).toBe(0);
            expect(parseInt(childCount.rows[0].count)).toBe(0);
            
            // Clean up tables
            await pool.query(`DROP TABLE IF EXISTS child_cleanup`);
            await pool.query(`DROP TABLE IF EXISTS parent_cleanup`);
        });
        
        it('should handle permission errors during cleanup', async () => {
            // This test simulates permission issues by creating a limited-permission user
            // Note: In a real test environment, you would need permission to create users
            
            const limitedUserName = 'limited_test_user';
            const limitedUserPassword = 'limited_password';
            
            try {
                // Create a limited permission user
                await pool.query(`
                    DO $$
                    BEGIN
                        IF NOT EXISTS (SELECT FROM pg_catalog.pg_roles WHERE rolname = '${limitedUserName}') THEN
                            CREATE USER ${limitedUserName} WITH PASSWORD '${limitedUserPassword}';
                        END IF;
                    END
                    $$;
                `);
                
                // Create a test table owned by postgres
                await pool.query(`CREATE TABLE IF NOT EXISTS restricted_table (id SERIAL PRIMARY KEY, data TEXT)`);
                
                // Grant only SELECT permission to the limited user
                await pool.query(`GRANT SELECT ON restricted_table TO ${limitedUserName}`);
                
                // Connect with the limited user
                const limitedPool = new Pool({
                    host: 'localhost',
                    port: 5433,
                    user: limitedUserName,
                    password: limitedUserPassword,
                    database: 'koutu-postgres-test',
                    connectionTimeoutMillis: 5000
                });
                
                try {
                    // Limited user should be able to query
                    const selectRes = await limitedPool.query(`SELECT * FROM restricted_table`);
                    expect(Array.isArray(selectRes.rows)).toBe(true);
                    
                    // But not truncate
                    await expect(
                        limitedPool.query(`TRUNCATE TABLE restricted_table`)
                    ).rejects.toThrow();
                    
                    // Demonstrate a robust cleanup approach with error handling
                    await pool.query(`
                        DO $$
                        BEGIN
                            BEGIN
                                TRUNCATE TABLE restricted_table;
                            EXCEPTION WHEN insufficient_privilege THEN
                                RAISE NOTICE 'Insufficient privilege to truncate, trying alternative cleanup';
                                -- Alternative cleanup logic could go here
                            END;
                        END
                        $$;
                    `);
                    
                } finally {
                    await limitedPool.end();
                }
                
            } catch (error) {
                console.log('Permission test skipped - requires admin privileges');
            } finally {
                // Clean up
                await pool.query(`DROP TABLE IF EXISTS restricted_table`);
                await pool.query(`
                    DO $$
                    BEGIN
                        IF EXISTS (SELECT FROM pg_catalog.pg_roles WHERE rolname = '${limitedUserName}') THEN
                            DROP OWNED BY ${limitedUserName};
                            DROP USER ${limitedUserName};
                        END IF;
                    END
                    $$;
                `).catch(() => {});
            }
        });
    });
});